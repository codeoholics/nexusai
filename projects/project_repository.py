import csv
import ast
import traceback

from db import db_client
from db.db_client import remove_table

from shared.resourcereader import get_absolute_path_from_resources
import shared.logger as logger

log = logger.get_logger(__name__)
plagiarism_threshold = 0.10
top_n = 10


def insert_project_into_db(project_data):
    try:
        # Set default values to None if any keys are missing
        data_with_defaults = {
            'project_type': project_data.get('project_type'),
            'title': project_data.get('title'),
            'description': project_data.get('description'),
            'summary_file': project_data.get('summary_file'),
            'members': project_data.get('members'),
            'institute': project_data.get('institute'),
            'prototype_demo': project_data.get('prototype_demo', None),
            'prototype_sourcecode': project_data.get('prototype_sourcecode', None),
            'categories': project_data.get('categories'),
            'theme': project_data.get('theme'),
            'domain': project_data.get('domain'),
            'uploaded_by': project_data.get('uploaded_by')
        }

        cursor = db_client.get_conn().cursor()

        insert_query = """INSERT INTO projects (project_type, title, description, summary_file, members, institute, prototype_demo, prototype_sourcecode, categories, theme, domain, uploaded_by)
        VALUES (%(project_type)s, %(title)s, %(description)s, %(summary_file)s, %(members)s, %(institute)s, %(prototype_demo)s, %(prototype_sourcecode)s, %(categories)s, %(theme)s, %(domain)s,  %(uploaded_by)s)
                RETURNING *;"""
        inserted_data = {}

        log.info(insert_query)
        log.info(data_with_defaults)

        cursor.execute(insert_query, data_with_defaults)
        inserted_row = cursor.fetchone()
        db_client.get_conn().commit()
        cursor.close()
        column_names = [desc[0] for desc in cursor.description]
        inserted_data = dict(zip(column_names, inserted_row))

        return inserted_data
    except Exception as e:
        raise Exception(f"Error inserting into database: {e}")


def insert_embeddings_to_old_project(projectid, embedding_type, embeddings):
    inserted_ids = []
    try:
        # Connect to the database
        with db_client.get_conn() as conn:
            with conn.cursor() as cursor:
                for embedding in embeddings:
                    log.info(embedding)
                    log.info(type(embedding))
                    log.info("inserting embedding")

                    cursor.execute(
                        "INSERT INTO project_vectors (project_id, embedding_type, embeddings) VALUES (%s, %s,%s)  RETURNING id",
                        (projectid, embedding_type, embedding)
                    )
                    inserted_id = cursor.fetchone()[0]  # Fetch the autogenerated ID
                    inserted_ids.append(inserted_id)  # Append the ID to the list

                conn.commit()
                return inserted_ids  # Return the list of inserted IDs


    except Exception as e:
        print(f"An error occurred: {e}")
        raise e
        # Handle or raise the exception as needed


def insert_embeddings_to_project(projectid, embedding_type, embeddings):
    inserted_ids = []
    try:
        # Connect to the database
        with db_client.get_conn() as conn:
            with conn.cursor() as cursor:
                log.info(embeddings)
                log.info(type(embeddings))
                log.info("inserting embedding")
                cursor.execute(
                    "INSERT INTO project_vectors (project_id, embedding_type, embeddings) VALUES (%s, %s,%s)  RETURNING id",
                    (projectid, embedding_type, embeddings)
                )
                inserted_id = cursor.fetchone()[0]  # Fetch the autogenerated ID
                inserted_ids.append(inserted_id)  # Append the ID to the list

                conn.commit()
                return inserted_ids  # Return the list of inserted IDs


    except Exception as e:
        print(f"An error occurred: {e}")
        raise e
        # Handle or raise the exception as needed


def recreate_project_vectors(dimensions=1536):
    try:
        # Connect to the database
        with db_client.get_conn() as conn:
            with conn.cursor() as cursor:
                remove_table("project_vectors")
                create_table_query = f"""
              CREATE TABLE project_vectors (
                id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
                project_id VARCHAR(255), 
                embedding_type VARCHAR(10) NOT NULL,
                date_created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                embeddings Vector({dimensions})
            )"""

                cursor.execute(create_table_query)
                db_client.get_conn().commit()
    except Exception as e:
        print(f"An error occurred: {e}")
        raise e


def get_unique_projects_with_similarity(project_data):
    unique_projects = {}
    for item in project_data:
        project_id = item['project_id']
        similarity = item['similarity']

        # Add the project to the dictionary if it's not already there
        if project_id not in unique_projects:
            unique_projects[project_id] = similarity

    # Convert the dictionary back to the desired list format
    unique_project_list = [{'project_id': project_id, 'similarity': similarity}
                           for project_id, similarity in unique_projects.items()]
    return unique_project_list



def find_similar_and_check_plagiarism(embedding_type, embedding):
    try:
        # Connect to the database
        with db_client.get_conn() as conn:
            with conn.cursor() as cursor:

                max_acceptable_distance = 8.9

                # [('23', 4.109220668665067)]
                # [('23', 0.0)]
                # TODO make sure the distance is greater than 2

                cursor.execute(
                    """
    SELECT *
    FROM (
        SELECT project_id, embeddings <-> %s::VECTOR AS similarity
        FROM project_vectors
    ) AS subquery
    WHERE similarity < %s
    ORDER BY similarity
    LIMIT %s
                   
     """,
                    (embedding, max_acceptable_distance, top_n)
                )
                rows = cursor.fetchall()
                log.info(rows)
                if rows:
                    column_names = [desc[0] for desc in cursor.description]
                    results = []

                    for row in rows:
                        row_dict = dict(zip(column_names, row))
                        similarity_score = row_dict['similarity']

                        percentile = calculate_similarity_percentile(similarity_score)

                        row_dict['similarity'] = percentile
                        results.append(row_dict)
                    return get_unique_projects_with_similarity(results)
                else:
                    return []


    except Exception as e:
        print(f"An error occurred: {e}")
        raise e


def calculate_similarity_percentile(similarity_score):
    # Calculate percentile (inverse mapping of similarity score)
    if similarity_score == 0:
        percentile = 100
    elif similarity_score >= 2:
        percentile = 0
    else:
        # Adjust this mapping as per your requirement
        percentile = 100 - (similarity_score / 2 * 100)
    return percentile


def initialize_projects_table():
    if db_client.check_table_exists("projects"):
        return
    """Create the projects table if it doesn't exist."""
    try:
        print(db_client.get_conn())
        cursor = db_client.get_conn().cursor()

        create_table_query = """
                      CREATE TABLE projects (
                        id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),

                    project_type VARCHAR(10) NOT NULL,
                    title TEXT NOT NULL,
                    uploaded_by VARCHAR(50) NOT NULL,
                    description TEXT,
                    summary_file TEXT,
                    members JSONB,
                    institute TEXT,
                    prototype_demo TEXT,
                    prototype_sourcecode TEXT,
                    categories JSONB,
                    theme VARCHAR(20),
                    domain VARCHAR(50),
                    date_created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    date_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    rating       INTEGER,
                    plagiarism_score INTEGER
                )"""

        cursor.execute(create_table_query)
        db_client.get_conn().commit()

        create_table_query = """
          CREATE TABLE project_vectors (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            project_id VARCHAR(255), 
            embedding_type VARCHAR(10) NOT NULL,
            date_created TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            embeddings Vector(768)
        )"""

        cursor.execute(create_table_query)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_project_id ON project_vectors (project_id);")

        # Create or replace index on embedding_type
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_embedding_type ON project_vectors (embedding_type);")

        # Create or replace composite index on project_id and embedding_type
        cursor.execute(
            "CREATE INDEX IF NOT EXISTS idx_project_id_embedding_type ON project_vectors (project_id, embedding_type);")

        db_client.get_conn().commit()

        cursor.close()

        print("Table projects and vectors created successfully!")
    except Exception as e:
        print(f"Error creating table: {e}")


def clean_project_data():
    remove_table("projects")
    remove_table("project_vectors")


def find_all_projects():
    try:
        cursor = db_client.get_conn().cursor()
        cursor.execute("SELECT * FROM projects")
        rows = cursor.fetchall()
        cursor.close()

        if rows:
            column_names = [desc[0] for desc in cursor.description]
            return [dict(zip(column_names, row)) for row in rows]
        else:
            return []
    except Exception as e:
        raise Exception(f"Error fetching all projects: {e}")


def find_projects_by_uploaded_by(uploaded_by):
    try:
        cursor = db_client.get_conn().cursor()
        cursor.execute("SELECT * FROM projects WHERE uploaded_by = %s", (uploaded_by,))
        rows = cursor.fetchall()
        cursor.close()

        if rows:
            column_names = [desc[0] for desc in cursor.description]
            return [dict(zip(column_names, row)) for row in rows]
        else:
            return []
    except Exception as e:
        raise Exception(f"Error fetching projects by uploaded_by: {e}")


def find_projects_by_categories(categories):
    try:
        cursor = db_client.get_conn().cursor()
        query = "SELECT * FROM projects WHERE categories @> %s::jsonb"
        cursor.execute(query, (json.dumps(categories),))
        rows = cursor.fetchall()
        cursor.close()

        if rows:
            column_names = [desc[0] for desc in cursor.description]
            return [dict(zip(column_names, row)) for row in rows]
        else:
            return []
    except Exception as e:
        raise Exception(f"Error fetching projects by categories: {e}")


def find_projects_by_domain(domain):
    try:
        cursor = db_client.get_conn().cursor()
        cursor.execute("SELECT * FROM projects WHERE domain = %s", (domain,))
        rows = cursor.fetchall()
        cursor.close()

        if rows:
            column_names = [desc[0] for desc in cursor.description]
            return [dict(zip(column_names, row)) for row in rows]
        else:
            return []
    except Exception as e:
        raise Exception(f"Error fetching projects by domain: {e}")


def search_projects_with_pagination(filters, page, per_page, sort_by='title', sort_type='asc'):
    valid_sort_columns = ['title', 'theme']
    sort_by = sort_by if sort_by in valid_sort_columns else 'title'
    sort_type = 'ASC' if sort_type.lower() == 'asc' else 'DESC'

    try:
        base_query = "SELECT * FROM projects WHERE TRUE"
        count_query = "SELECT COUNT(*) FROM projects WHERE TRUE"
        query_params = []

        # Adding filters
        for filter_key, filter_value in filters.items():
            if filter_value:
                if filter_key in ['categories', 'members']:
                    # Special handling for JSONB fields
                    base_query += f" AND {filter_key} @> %s::jsonb"
                    count_query += f" AND {filter_key} @> %s::jsonb"
                else:
                    base_query += f" AND {filter_key} = %s"
                    count_query += f" AND {filter_key} = %s"
                query_params.append(filter_value)

        # Sorting
        base_query += f" ORDER BY {sort_by} {sort_type}"

        # Pagination
        offset = (page - 1) * per_page
        base_query += " LIMIT %s OFFSET %s"
        count_query += " LIMIT %s OFFSET %s"

        query_params.extend([per_page, offset])
        # Execute search query
        cursor = db_client.get_conn().cursor()
        cursor.execute(base_query, query_params)
        rows = cursor.fetchall()
        results = [dict(zip([desc[0] for desc in cursor.description], row)) for row in rows] if rows else []

        # Execute count query

        cursor.execute(count_query, query_params)
        total_records = cursor.fetchone()[0]

        cursor.close()

        return {
            "results": results,
            "total_records": total_records,
            "page": page,
            "per_page": per_page,
            "total_pages": (total_records + per_page - 1) // per_page
        }
    except Exception as e:

        log.error(f"Error searching projects with pagination: {e}")
        traceback.print_exc()
        raise e
        # raise Exception(f"Error searching projects with pagination: {e}")


def find_project_by_id(project_id):
    try:
        cursor = db_client.get_conn().cursor()
        cursor.execute("SELECT * FROM projects WHERE id = %s", (project_id,))
        row = cursor.fetchone()
        cursor.close()

        if row:
            column_names = [desc[0] for desc in cursor.description]
            return dict(zip(column_names, row))
        else:
            return None
    except Exception as e:
        raise Exception(f"Error fetching project by id: {e}")
